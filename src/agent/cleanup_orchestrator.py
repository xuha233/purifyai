# -*- coding: utf-8 -*-
"""
æ¸…ç†æµç¨‹ç¼–æ’æ¨¡å— (Cleanup Orchestrator)

å®ç°ä¸€é”®æ¸…ç†æµç¨‹çš„ç¼–æ’ã€é¢„è§ˆã€æ‰§è¡Œå’ŒæŠ¥å‘Šç”Ÿæˆ

ä½œè€…: å°åˆ ğŸ¦
åˆ›å»ºæ—¶é—´: 2026-02-24
"""

import uuid
import json
import logging
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Any, Set
from datetime import datetime
from enum import Enum
from pathlib import Path
import time
import os

from PyQt5.QtCore import QObject, pyqtSignal

from .smart_recommender import SmartRecommender, UserProfile, CleanupPlan, CleanupMode
from ..core.models import ScanItem
from ..core.backup_manager import BackupManager
from ..core.cleaner import Cleaner

logger = logging.getLogger(__name__)


# ============================================================================
# æšä¸¾å®šä¹‰
# ============================================================================

class CleanupPhase(Enum):
    """æ¸…ç†é˜¶æ®µ"""
    SCANNING = "scanning"           # æ‰«æä¸­
    ANALYZING = "analyzing"         # åˆ†æä¸­
    BACKING_UP = "backing_up"       # å¤‡ä»½ä¸­
    CLEANING = "cleaning"           # æ¸…ç†ä¸­
    COMPLETED = "completed"         # å·²å®Œæˆ
    FAILED = "failed"               # å¤±è´¥

    def get_display_name(self) -> str:
        """è·å–æ˜¾ç¤ºåç§°"""
        names = {
            CleanupPhase.SCANNING: "æ‰«æä¸­",
            CleanupPhase.ANALYZING: "åˆ†æä¸­",
            CleanupPhase.BACKING_UP: "å¤‡ä»½ä¸­",
            CleanupPhase.CLEANING: "æ¸…ç†ä¸­",
            CleanupPhase.COMPLETED: "å·²å®Œæˆ",
            CleanupPhase.FAILED: "å¤±è´¥"
        }
        return names.get(self, self.value)


# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

@dataclass
class CleanupReport:
    """æ¸…ç†æŠ¥å‘Š"""
    report_id: str
    plan_id: str
    started_at: datetime
    completed_at: Optional[datetime] = None
    duration_seconds: float = 0.0
    total_items: int = 0
    success_items: int = 0
    failed_items: int = 0
    freed_size: int = 0
    success_rate: float = 0.0
    details: List[Dict[str, Any]] = field(default_factory=list)
    phase: CleanupPhase = CleanupPhase.SCANNING
    is_incremental: bool = False  # æ˜¯å¦ä¸ºå¢é‡æ¸…ç†

    # å¢é‡æ¸…ç†ç»Ÿè®¡
    new_files_count: int = 0  # æ–°å¢æ–‡ä»¶æ•°
    skipped_files_count: int = 0  # è·³è¿‡æ–‡ä»¶æ•°ï¼ˆä¸Šæ¬¡å·²æ¸…ç†ï¼‰
    last_cleanup_time: Optional[datetime] = None  # ä¸Šæ¬¡æ¸…ç†æ—¶é—´
    speed_improvement: float = 0.0  # é€Ÿåº¦æå‡ç™¾åˆ†æ¯”

    def calculate_stats(self):
        """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
        self.total_items = len(self.details)
        self.success_items = sum(1 for d in self.details if d.get('success', False))
        self.failed_items = sum(1 for d in self.details if not d.get('success', False))
        self.freed_size = sum(d.get('freed_size', 0) for d in self.details if d.get('success', False))

        if self.total_items > 0:
            self.success_rate = (self.success_items / self.total_items) * 100

        if self.completed_at:
            self.duration_seconds = (self.completed_at - self.started_at).total_seconds()

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'report_id': self.report_id,
            'plan_id': self.plan_id,
            'started_at': self.started_at.isoformat(),
            'completed_at': self.completed_at.isoformat() if self.completed_at else None,
            'duration_seconds': self.duration_seconds,
            'total_items': self.total_items,
            'success_items': self.success_items,
            'failed_items': self.failed_items,
            'freed_size': self.freed_size,
            'success_rate': self.success_rate,
            'phase': self.phase.value,
            'details': self.details
        }


@dataclass
class BackupInfo:
    """å¤‡ä»½ä¿¡æ¯"""
    backup_id: str
    items_count: int
    total_size: int
    backup_path: str
    started_at: datetime
    completed_at: Optional[datetime] = None

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'backup_id': self.backup_id,
            'items_count': self.items_count,
            'total_size': self.total_size,
            'backup_path': self.backup_path,
            'started_at': self.started_at.isoformat(),
            'completed_at': self.completed_at.isoformat() if self.completed_at else None
        }


# ============================================================================
# æ¸…ç†ä¿¡å·
# ============================================================================

class CleanupSignal(QObject):
    """æ¸…ç†ä¿¡å·ï¼ˆç”¨äºæ›´æ–° UIï¼‰"""

    # è¿›åº¦æ›´æ–°ï¼š(ç™¾åˆ†æ¯”, å½“å‰çŠ¶æ€æè¿°)
    progress_updated = pyqtSignal(int, str)

    # é˜¶æ®µå˜åŒ–ï¼š'scanning', 'analyzing', 'backing_up', 'cleaning', 'completed', 'failed'
    phase_changed = pyqtSignal(str)

    # æ¸…ç†å®Œæˆï¼šæ¸…ç†æŠ¥å‘Š
    cleanup_completed = pyqtSignal(CleanupReport)

    # æ¸…ç†å¤±è´¥ï¼šé”™è¯¯æ¶ˆæ¯
    cleanup_failed = pyqtSignal(str)

    # å¤‡ä»½è¿›åº¦ï¼š(å½“å‰é¡¹ç›®æ•°, æ€»é¡¹ç›®æ•°)
    backup_progress = pyqtSignal(int, int)

    # æ¸…ç†çŠ¶æ€ï¼šï¼ˆé¡¹ç›®è·¯å¾„, æˆåŠŸ/å¤±è´¥ï¼‰
    cleanup_status = pyqtSignal(str, bool)


# ============================================================================
# æ¸…ç†æµç¨‹ç¼–æ’å™¨
# ============================================================================

class CleanupOrchestrator:
    """æ¸…ç†æµç¨‹ç¼–æ’å™¨

    åŠŸèƒ½ï¼š
    1. æ‰§è¡Œä¸€é”®æ¸…ç†å®Œæ•´æµç¨‹
    2. ç”Ÿæˆæ¸…ç†è®¡åˆ’é¢„è§ˆ
    3. æ¸…ç†å‰è‡ªåŠ¨å¤‡ä»½
    4. æ‰§è¡Œæ¸…ç†å¹¶ç”ŸæˆæŠ¥å‘Š
    5. æ”¯æŒå¢é‡æ¸…ç†
    """

    def __init__(self, profile: UserProfile, signal: Optional[CleanupSignal] = None):
        """åˆå§‹åŒ–æ¸…ç†ç¼–æ’å™¨

        Args:
            profile: ç”¨æˆ·ç”»åƒ
            signal: æ¸…ç†ä¿¡å·ï¼ˆç”¨äº UI æ›´æ–°ï¼‰
        """
        self.profile = profile
        self.recommender = SmartRecommender()
        self.backup_manager = BackupManager()
        self.cleaner = Cleaner()
        self.signal = signal
        self._incremental_stats = None  # ç¼“å­˜å¢é‡ç»Ÿè®¡ä¿¡æ¯

    def execute_incremental_cleanup(self, mode: str = CleanupMode.BALANCED.value) -> CleanupReport:
        """æ‰§è¡Œå¢é‡æ¸…ç†

        åªæ¸…ç†ä¸Šæ¬¡æ¸…ç†åæ–°å¢çš„å¯æ¸…ç†æ–‡ä»¶ï¼Œæé«˜æ¸…ç†æ•ˆç‡ã€‚

        æ­¥éª¤ï¼š
        1. ä½¿ç”¨æ¨èå™¨è·å–å¢é‡æ¸…ç†è®¡åˆ’
        2. è·å–ä¸Šæ¬¡æ¸…ç†çš„æ–‡ä»¶åˆ—è¡¨
        3. è®¡ç®—æ–°å¢/è·³è¿‡æ–‡ä»¶ç»Ÿè®¡
        4. æ˜¾ç¤ºé¢„è§ˆ
        5. è‡ªåŠ¨å¤‡ä»½
        6. æ‰§è¡Œæ¸…ç†
        7. ç”ŸæˆæŠ¥å‘Š
        8. æ¸…ç†åè‡ªåŠ¨ä¿å­˜æ–‡ä»¶åˆ—è¡¨

        Args:
            mode: æ¸…ç†æ¨¡å¼ï¼ˆé»˜è®¤ä¸ºå¹³è¡¡æ¨¡å¼ï¼‰

        Returns:
            CleanupReport: æ¸…ç†æŠ¥å‘Šï¼ŒåŒ…å«å¢é‡æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
        """
        report_id = str(uuid.uuid4())
        start_time = datetime.now()

        report = CleanupReport(
            report_id=report_id,
            plan_id="",
            started_at=start_time,
            phase=CleanupPhase.SCANNING,
            is_incremental=True
        )

        try:
            logger.info(f"[CleanupOrchestrator] å¼€å§‹å¢é‡æ¸…ç† (report_id: {report_id})")

            # é˜¶æ®µ 1ï¼šæ‰«æå’Œåˆ†æï¼ˆå¢é‡æ¨¡å¼ï¼‰
            self._update_phase(CleanupPhase.SCANNING, 10, "æ­£åœ¨æ‰«ææ–°å¢åƒåœ¾æ–‡ä»¶...")
            plan = self.recommender.recommend_incremental(mode)
            report.plan_id = plan.plan_id

            # è·å–ä¸Šæ¬¡æ¸…ç†çš„æ–‡ä»¶å’Œä¿¡æ¯
            last_cleanup_files = set(self.recommender.load_last_cleanup_files())
            last_cleanup_time = self._get_last_cleanup_time()

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            new_files_count = len(plan.items)
            total_cleanable = new_files_count + len(last_cleanup_files)
            skipped_files_count = len(last_cleanup_files)

            report.new_files_count = new_files_count
            report.skipped_files_count = skipped_files_count
            report.last_cleanup_time = last_cleanup_time

            logger.info(
                f"[IncrementalCleanup] æ–°å¢æ–‡ä»¶: {new_files_count}, "
                f"è·³è¿‡æ–‡ä»¶: {skipped_files_count}, "
                f"æ€»å¯æ¸…ç†: {total_cleanable}"
            )

            self._update_phase(CleanupPhase.ANALYZING, 20, f"åˆ†æå®Œæˆ: æ–°å¢ {new_files_count} ä¸ªæ–‡ä»¶...")

            # é˜¶æ®µ 2ï¼šå¤‡ä»½ï¼ˆåªå¤‡ä»½æ–°å¢æ–‡ä»¶ï¼‰
            if len(plan.items) > 0:
                self._update_phase(CleanupPhase.BACKING_UP, 30, f"æ­£åœ¨å¤‡ä»½ {new_files_count} ä¸ªæ–°æ–‡ä»¶...")
                backup_info = self.backup_before_cleanup(plan.items)
                report.details.append({
                    'type': 'backup',
                    'backup_id': backup_info.backup_id,
                    'items_count': backup_info.items_count,
                    'total_size': backup_info.total_size
                })
            else:
                logger.info("[IncrementalCleanup] æ²¡æœ‰æ–°å¢æ–‡ä»¶éœ€è¦æ¸…ç†")
                report.phase = CleanupPhase.COMPLETED
                report.completed_at = datetime.now()
                report.calculate_stats()
                return report

            # é˜¶æ®µ 3ï¼šæ‰§è¡Œæ¸…ç†
            self._update_phase(CleanupPhase.CLEANING, 50, f"æ­£åœ¨æ¸…ç† {new_files_count} ä¸ªæ–°æ–‡ä»¶...")
            report = self.execute_cleanup(plan, backup_info.backup_id)

            # é˜¶æ®µ 4ï¼šç”ŸæˆæŠ¥å‘Šå’Œä¿å­˜å¢é‡ä¿¡æ¯
            self._update_phase(CleanupPhase.COMPLETED, 90, "æ­£åœ¨ä¿å­˜å¢é‡è®°å½•...")

            # ä¿å­˜æ¸…ç†çš„æ–‡ä»¶åˆ—è¡¨
            cleaned_files = [
                d.get('path') for d in report.details
                if d.get('success', False) and d.get('path')
            ]

            if cleaned_files:
                self.recommender.save_last_cleanup_files(cleaned_files)
                logger.info(f"[IncrementalCleanup] å·²ä¿å­˜ {len(cleaned_files)} ä¸ªæ–‡ä»¶åˆ°å¢é‡è®°å½•")

            # è®¡ç®—é€Ÿåº¦æå‡ï¼ˆåŸºäºæ–‡ä»¶æ•°é‡å‡å°‘ï¼‰
            if total_cleanable > 0:
                report.speed_improvement = (skipped_files_count / total_cleanable) * 100
                logger.info(
                    f"[IncrementalCleanup] é€Ÿåº¦æå‡: {report.speed_improvement:.1f}% "
                    f"(è·³è¿‡ {skipped_files_count}/{total_cleanable} ä¸ªæ–‡ä»¶)"
                )

            # é˜¶æ®µ 5ï¼šå®Œæˆ
            self._update_phase(CleanupPhase.COMPLETED, 100, "å¢é‡æ¸…ç†å®Œæˆï¼")
            report.phase = CleanupPhase.COMPLETED
            report.calculate_stats()
            report.completed_at = datetime.now()

            # ä¿å­˜æ¸…ç†å†å²ï¼ˆåŒ…å«å¢é‡ä¿¡æ¯ï¼‰
            self._save_cleanup_history(report)

            logger.info(
                f"[CleanupOrchestrator] å¢é‡æ¸…ç†å®Œæˆ: "
                f"{report.success_items} ä¸ªæˆåŠŸ, "
                f"é‡Šæ”¾ {self._format_size(report.freed_size)}"
            )

            return report

        except Exception as e:
            report.phase = CleanupPhase.FAILED
            report.details.append({
                'type': 'error',
                'error': str(e)
            })

            logger.error(f"[CleanupOrchestrator] å¢é‡æ¸…ç†å¤±è´¥: {e}", exc_info=True)

            if self.signal:
                self.signal.cleanup_failed.emit(str(e))

            raise e

    def _get_last_cleanup_time(self) -> Optional[datetime]:
        """è·å–æœ€åä¸€æ¬¡æ¸…ç†æ—¶é—´ï¼ˆç”¨äºå¢é‡æ¸…ç†ï¼‰"""
        history_file = os.path.join(os.path.expanduser('~'), '.purifyai', 'cleanup_history.json')

        if os.path.exists(history_file):
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    last_time = data.get('last_cleanup')
                    if last_time:
                        return datetime.fromisoformat(last_time)
            except Exception as e:
                logger.warning(f"[CleanupOrchestrator] è·å–ä¸Šæ¬¡æ¸…ç†æ—¶é—´å¤±è´¥: {e}")

        return None

    def execute_one_click_cleanup(self, mode: str = CleanupMode.BALANCED.value) -> CleanupReport:
        """æ‰§è¡Œä¸€é”®æ¸…ç†

        æ­¥éª¤ï¼š
        1. ç”Ÿæˆæ¸…ç†è®¡åˆ’
        2. æ˜¾ç¤ºé¢„è§ˆ
        3. è‡ªåŠ¨å¤‡ä»½
        4. æ‰§è¡Œæ¸…ç†
        5. ç”ŸæˆæŠ¥å‘Š
        """
        report_id = str(uuid.uuid4())
        report = CleanupReport(
            report_id=report_id,
            plan_id="",
            started_at=datetime.now(),
            phase=CleanupPhase.SCANNING
        )

        try:
            # é˜¶æ®µ 1ï¼šæ‰«æå’Œåˆ†æ
            self._update_phase(CleanupPhase.SCANNING, 10, "æ­£åœ¨æ‰«æç³»ç»Ÿ...")
            plan = self.generate_cleanup_plan(mode)
            report.plan_id = plan.plan_id
            report.is_incremental = plan.is_incremental

            self._update_phase(CleanupPhase.ANALYZING, 20, "æ­£åœ¨åˆ†ææ–‡ä»¶é£é™©...")
            # è®¡åˆ’å·²åœ¨ recommend ä¸­ç”Ÿæˆ

            # é˜¶æ®µ 2ï¼šå¤‡ä»½
            self._update_phase(CleanupPhase.BACKING_UP, 30, "æ­£åœ¨å¤‡ä»½æ–‡ä»¶...")
            backup_info = self.backup_before_cleanup(plan.items)
            report.details.append({
                'type': 'backup',
                'backup_id': backup_info.backup_id,
                'items_count': backup_info.items_count,
                'total_size': backup_info.total_size
            })

            # é˜¶æ®µ 3ï¼šæ‰§è¡Œæ¸…ç†
            self._update_phase(CleanupPhase.CLEANING, 50, "æ­£åœ¨æ¸…ç†æ–‡ä»¶...")
            report = self.execute_cleanup(plan, backup_info.backup_id)

            # é˜¶æ®µ 4ï¼šç”ŸæˆæŠ¥å‘Š
            self._update_phase(CleanupPhase.COMPLETED, 100, "æ¸…ç†å®Œæˆï¼")
            report.phase = CleanupPhase.COMPLETED
            report.calculate_stats()

            # ä¿å­˜æ¸…ç†å†å²
            self._save_cleanup_history(report)

            return report

        except Exception as e:
            report.phase = CleanupPhase.FAILED
            report.details.append({
                'type': 'error',
                'error': str(e)
            })

            if self.signal:
                self.signal.cleanup_failed.emit(str(e))

            raise e

    def generate_cleanup_plan(self, mode: str = CleanupMode.BALANCED.value) -> CleanupPlan:
        """ç”Ÿæˆæ¸…ç†è®¡åˆ’ï¼ˆé¢„è§ˆç”¨ï¼‰"""
        plan = self.recommender.recommend(self.profile, mode)
        return plan

    def preview_cleanup(self, plan: CleanupPlan) -> Dict[str, Any]:
        """ç”Ÿæˆæ¸…ç†é¢„è§ˆ"""
        return {
            'plan_id': plan.plan_id,
            'total_items': len(plan.items),
            'estimated_space': self._format_size(plan.estimated_space),
            'high_risk_count': plan.high_risk_count,
            'medium_risk_count': plan.medium_risk_count,
            'low_risk_count': plan.low_risk_count,
            'risk_percentage': plan.risk_percentage,
            'recommended': plan.recommended,
            'mode': CleanupMode(plan.mode).get_display_name()
        }

    def backup_before_cleanup(self, items: List[ScanItem]) -> BackupInfo:
        """æ¸…ç†å‰è‡ªåŠ¨å¤‡ä»½"""
        backup_id = str(uuid.uuid4())
        backup_path = os.path.join(os.path.expanduser('~'), '.purifyai', 'backups', backup_id)

        os.makedirs(backup_path, exist_ok=True)

        total_count = len(items)
        total_size = sum(item.size for item in items)

        started_at = datetime.now()

        for i, item in enumerate(items):
            try:
                # ä½¿ç”¨å¤‡ä»½ç®¡ç†å™¨åˆ›å»ºå¤‡ä»½
                backup_file = self.backup_manager.backup_file(
                    item.path,
                    backup_path=backup_path
                )

                if self.signal:
                    self.signal.backup_progress.emit(i + 1, total_count)

            except Exception as e:
                print(f"[CleanupOrchestrator] å¤‡ä»½å¤±è´¥: {item.path}, é”™è¯¯: {e}")

        completed_at = datetime.now()

        backup_info = BackupInfo(
            backup_id=backup_id,
            items_count=total_count,
            total_size=total_size,
            backup_path=backup_path,
            started_at=started_at,
            completed_at=completed_at
        )

        return backup_info

    def execute_cleanup(self, plan: CleanupPlan, backup_id: str) -> CleanupReport:
        """æ‰§è¡Œæ¸…ç†"""
        report_id = str(uuid.uuid4())
        report = CleanupReport(
            report_id=report_id,
            plan_id=plan.plan_id,
            started_at=datetime.now(),
            phase=CleanupPhase.CLEANING
        )

        total_items = len(plan.items)

        for i, item in enumerate(plan.items):
            try:
                # ä½¿ç”¨æ¸…ç†å™¨å®‰å…¨åˆ é™¤
                result = self.cleaner.delete_secure(item.path, backup_id=backup_id)

                success = bool(result and result.get('success', False))
                freed_size = result.get('freed_size', 0) if success else 0

                report.details.append({
                    'type': 'cleanup',
                    'path': item.path,
                    'success': success,
                    'freed_size': freed_size,
                    'error': None if success else result.get('error', 'Unknown error')
                })

                if self.signal:
                    self.signal.cleanup_status.emit(item.path, success)

                # æ›´æ–°è¿›åº¦
                progress = 50 + int((i + 1) / total_items * 50)
                percent = min(progress, 95)
                status = f"æ­£åœ¨æ¸…ç† ({i + 1}/{total_items}): {os.path.basename(item.path)}"
                self._update_progress(percent, status)

            except Exception as e:
                report.details.append({
                    'type': 'cleanup',
                    'path': item.path,
                    'success': False,
                    'freed_size': 0,
                    'error': str(e)
                })

                if self.signal:
                    self.signal.cleanup_status.emit(item.path, False)

        report.calculate_stats()
        report.completed_at = datetime.now()

        return report

    def _update_phase(self, phase: CleanupPhase, progress: int, status: str):
        """æ›´æ–°æ¸…ç†é˜¶æ®µ"""
        if self.signal:
            self.signal.phase_changed.emit(phase.value)
            self._update_progress(progress, status)

    def _update_progress(self, percent: int, status: str):
        """æ›´æ–°è¿›åº¦"""
        if self.signal:
            self.signal.progress_updated.emit(percent, status)

    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.2f} PB"

    def _save_cleanup_history(self, report: CleanupReport):
        """ä¿å­˜æ¸…ç†å†å²"""
        history_file = os.path.join(os.path.expanduser('~'), '.purifyai', 'cleanup_history.json')
        history_dir = os.path.dirname(history_file)
        os.makedirs(history_dir, exist_ok=True)

        try:
            data = {}
            if os.path.exists(history_file):
                with open(history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

            if 'history' not in data:
                data['history'] = []

            # è½¬æ¢ä¸ºå­—å…¸ï¼ŒåŒ…å«å¢é‡æ¸…ç†ç»Ÿè®¡
            report_dict = report.to_dict()
            if report.is_incremental:
                report_dict.update({
                    'new_files_count': report.new_files_count,
                    'skipped_files_count': report.skipped_files_count,
                    'last_cleanup_time': report.last_cleanup_time.isoformat() if report.last_cleanup_time else None,
                    'speed_improvement': report.speed_improvement
                })

            data['history'].append(report_dict)
            data['last_cleanup'] = datetime.now().isoformat()

            # åªä¿ç•™æœ€è¿‘ 100 æ¡è®°å½•
            if len(data['history']) > 100:
                data['history'] = data['history'][-100:]

            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            # è®°å½•å¢é‡æ¸…ç†å†å²åˆ°æ—¥å¿—
            if report.is_incremental:
                self._log_incremental_cleanup_history(report)

        except Exception as e:
            logger.error(f"[CleanupOrchestrator] ä¿å­˜å†å²å¤±è´¥: {e}", exc_info=True)

    def _log_incremental_cleanup_history(self, report: CleanupReport):
        """è®°å½•å¢é‡æ¸…ç†åˆ°ä¸“ç”¨æ—¥å¿—"""
        try:
            incremental_log_file = os.path.join(
                os.path.expanduser('~'), '.purifyai', 'incremental_cleanup.log'
            )

            log_dir = os.path.dirname(incremental_log_file)
            os.makedirs(log_dir, exist_ok=True)

            with open(incremental_log_file, 'a', encoding='utf-8') as f:
                timestamp = datetime.now().isoformat()
                log_entry = (
                    f"[{timestamp}] Report ID: {report.report_id}\n"
                    f"  - æ–°å¢æ–‡ä»¶: {report.new_files_count}\n"
                    f"  - è·³è¿‡æ–‡ä»¶: {report.skipped_files_count}\n"
                    f"  - æˆåŠŸæ¸…ç†: {report.success_items}\n"
                    f"  - é‡Šæ”¾ç©ºé—´: {self._format_size(report.freed_size)}\n"
                    f"  - é€Ÿåº¦æå‡: {report.speed_improvement:.1f}%\n"
                    f"  - è€—æ—¶: {report.duration_seconds:.2f} ç§’\n"
                    f"  - ä¸Šæ¬¡æ¸…ç†: {report.last_cleanup_time or 'æœªçŸ¥'}\n"
                    f"{'=' * 60}\n"
                )
                f.write(log_entry)

            logger.info(f"[CleanupOrchestrator] å¢é‡æ¸…ç†å†å²å·²è®°å½•åˆ° {incremental_log_file}")

        except Exception as e:
            logger.warning(f"[CleanupOrchestrator] è®°å½•å¢é‡æ¸…ç†å†å²å¤±è´¥: {e}")


# å¯¼å…¥ os æ¨¡å—
import os
