# -*- coding: utf-8 -*-
"""
è§„åˆ™ç®¡ç†å™¨ (Rule Manager)

ç®¡ç†è§„åˆ™çš„å¢åˆ æ”¹æŸ¥ã€å¯¼å…¥å¯¼å‡ºã€æŒä¹…åŒ–å­˜å‚¨

ä½œè€…: å°åˆ ğŸ¦
åˆ›å»ºæ—¶é—´: 2026-02-24
"""

from __future__ import annotations

import json
import uuid
import os
import logging
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any

from .cleanup_rule import (
    CleanupRule, RuleType, RuleAction, ConditionType, RuleOperator
)
from .rule_engine import RuleEngine, create_simple_rule

logger = logging.getLogger(__name__)


# ============================================================================
# è§„åˆ™ç®¡ç†å™¨ç±»
# ============================================================================

class RuleManager:
    """è§„åˆ™ç®¡ç†å™¨ç±»

    è´Ÿè´£è§„åˆ™çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†
    """

    def __init__(self, config_dir: str = "src/config"):
        """åˆå§‹åŒ–è§„åˆ™ç®¡ç†å™¨

        Args:
            config_dir: é…ç½®æ–‡ä»¶ç›®å½•
        """
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(parents=True, exist_ok=True)

        # è§„åˆ™æ–‡ä»¶è·¯å¾„
        self.rules_file = self.config_dir / "cleanup_rules.json"
        self.preset_rules_file = self.config_dir / "preset_rules.json"
        self.backup_dir = self.config_dir / "rules_backup"
        self.backup_dir.mkdir(parents=True, exist_ok=True)

        # è§„åˆ™å¼•æ“
        self.engine = RuleEngine()

        # è§„åˆ™åˆ—è¡¨ï¼ˆå·²åŠ è½½çš„ï¼‰
        self._rules: Dict[str, CleanupRule] = {}

        # è‡ªåŠ¨åŠ è½½
        self.load_all_rules()

    # ------------------------------------------------------------------------
    # CRUD æ“ä½œ
    # ------------------------------------------------------------------------

    def add_rule(self, rule: CleanupRule) -> str:
        """æ·»åŠ è§„åˆ™

        Args:
            rule: æ¸…ç†è§„åˆ™å¯¹è±¡

        Returns:
            è§„åˆ™ ID

        Raises:
            ValueError: è§„åˆ™ ID å·²å­˜åœ¨
        """
        if rule.rule_id in self._rules:
            raise ValueError(f"è§„åˆ™ ID å·²å­˜åœ¨: {rule.rule_id}")

        # è‡ªåŠ¨ç”Ÿæˆ IDï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
        if not rule.rule_id:
            rule.rule_id = str(uuid.uuid4())

        self._rules[rule.rule_id] = rule
        self._save_rules()

        # åŠ è½½åˆ°å¼•æ“
        self.engine.load_rules([rule])

        logger.info(f"æ·»åŠ è§„åˆ™: {rule.rule_name} ({rule.rule_id})")
        return rule.rule_id

    def update_rule(self, rule_id: str, rule: CleanupRule) -> bool:
        """æ›´æ–°è§„åˆ™

        Args:
            rule_id: è§„åˆ™ ID
            rule: æ–°çš„è§„åˆ™å¯¹è±¡

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if rule_id not in self._rules:
            logger.warning(f"è§„åˆ™ä¸å­˜åœ¨: {rule_id}")
            return False

        # å¤‡ä»½åŸè§„åˆ™
        self._backup_rule(rule_id)

        # æ›´æ–°
        rule.rule_id = rule_id  # ç¡®ä¿ä¸€è‡´
        rule.updated_at = datetime.now()
        self._rules[rule_id] = rule

        self._save_rules()

        # é‡æ–°åŠ è½½åˆ°å¼•æ“
        self._reload_rules_to_engine()

        logger.info(f"æ›´æ–°è§„åˆ™: {rule.rule_name} ({rule_id})")
        return True

    def delete_rule(self, rule_id: str) -> bool:
        """åˆ é™¤è§„åˆ™

        Args:
            rule_id: è§„åˆ™ ID

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if rule_id not in self._rules:
            logger.warning(f"è§„åˆ™ä¸å­˜åœ¨: {rule_id}")
            return False

        rule = self._rules.pop(rule_id, None)
        if rule:
            logger.info(f"åˆ é™¤è§„åˆ™: {rule.rule_name} ({rule_id})")

        self._save_rules()

        # é‡æ–°åŠ è½½åˆ°å¼•æ“
        self._reload_rules_to_engine()

        return True

    def get_rule(self, rule_id: str) -> Optional[CleanupRule]:
        """è·å–è§„åˆ™

        Args:
            rule_id: è§„åˆ™ ID

        Returns:
            CleanupRule å¯¹è±¡æˆ– None
        """
        return self._rules.get(rule_id)

    def list_rules(self, enabled_only: bool = False) -> List[CleanupRule]:
        """åˆ—å‡ºæ‰€æœ‰è§„åˆ™

        Args:
            enabled_only: æ˜¯å¦ä»…è¿”å›å¯ç”¨çš„è§„åˆ™

        Returns:
            è§„åˆ™åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
        """
        rules = list(self._rules.values())

        if enabled_only:
            rules = [r for r in rules if r.is_enabled]

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        rules.sort(key=lambda r: r.priority)
        return rules

    def enable_rule(self, rule_id: str) -> bool:
        """å¯ç”¨è§„åˆ™

        Args:
            rule_id: è§„åˆ™ ID

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        return self._set_rule_enabled(rule_id, True)

    def disable_rule(self, rule_id: str) -> bool:
        """ç¦ç”¨è§„åˆ™

        Args:
            rule_id: è§„åˆ™ ID

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        return self._set_rule_enabled(rule_id, False)

    def _set_rule_enabled(self, rule_id: str, enabled: bool) -> bool:
        """è®¾ç½®è§„åˆ™å¯ç”¨çŠ¶æ€ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        Args:
            rule_id: è§„åˆ™ ID
            enabled: æ˜¯å¦å¯ç”¨

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if rule_id not in self._rules:
            logger.warning(f"è§„åˆ™ä¸å­˜åœ¨: {rule_id}")
            return False

        self._rules[rule_id].is_enabled = enabled
        self._rules[rule_id].updated_at = datetime.now()
        self._save_rules()
        self._reload_rules_to_engine()

        logger.info(f"{'å¯ç”¨' if enabled else 'ç¦ç”¨'}è§„åˆ™: {rule_id}")
        return True

    def reorder_rules(self, rule_ids: List[str]) -> bool:
        """é‡æ–°æ’åºè§„åˆ™

        Args:
            rule_ids: æŒ‰ä¼˜å…ˆçº§æ’åºçš„è§„åˆ™ ID åˆ—è¡¨

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # éªŒè¯æ‰€æœ‰ ID éƒ½å­˜åœ¨
        missing_ids = set(rule_ids) - set(self._rules.keys())
        if missing_ids:
            logger.warning(f"è§„åˆ™ä¸å­˜åœ¨: {missing_ids}")
            return False

        # åˆ†é…æ–°ä¼˜å…ˆçº§
        for idx, rule_id in enumerate(rule_ids):
            if rule_id in self._rules:
                self._rules[rule_id].priority = idx
                self._rules[rule_id].updated_at = datetime.now()

        self._save_rules()
        self._reload_rules_to_engine()

        logger.info(f"é‡æ–°æ’åºäº† {len(rule_ids)} æ¡è§„åˆ™")
        return True

    # ------------------------------------------------------------------------
    # å¯¼å…¥/å¯¼å‡º
    # ------------------------------------------------------------------------

    def export_rules(self, file_path: str, rule_ids: Optional[List[str]] = None) -> bool:
        """å¯¼å‡ºè§„åˆ™åˆ°æ–‡ä»¶

        Args:
            file_path: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
            rule_ids: å¯é€‰ï¼Œä»…å¯¼å‡ºæŒ‡å®šè§„åˆ™

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç¡®å®šè¦å¯¼å‡ºçš„è§„åˆ™
            if rule_ids:
                rules_to_export = [self._rules[rid] for rid in rule_ids if rid in self._rules]
            else:
                rules_to_export = list(self._rules.values())

            # å¯¼å‡º
            export_data = {
                'version': '1.0',
                'exported_at': datetime.now().isoformat(),
                'count': len(rules_to_export),
                'rules': [rule.to_dict() for rule in rules_to_export]
            }

            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)

            logger.info(f"å¯¼å‡º {len(rules_to_export)} æ¡è§„åˆ™åˆ° {file_path}")
            return True
        except (OSError, IOError) as e:
            logger.error(f"å¯¼å‡ºè§„åˆ™å¤±è´¥: {e}")
            return False

    def import_rules(
        self,
        file_path: str,
        merge_strategy: str = "skip"
    ) -> tuple[int, List[str], List[str]]:
        """ä»æ–‡ä»¶å¯¼å…¥è§„åˆ™

        Args:
            file_path: å¯¼å…¥æ–‡ä»¶è·¯å¾„
            merge_strategy: åˆå¹¶ç­–ç•¥ï¼ˆskip | overwrite | skip_all | overwrite_allï¼‰

        Returns:
            (æˆåŠŸå¯¼å…¥æ•°, è·³è¿‡åˆ—è¡¨, è¦†ç›–åˆ—è¡¨)
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if 'rules' not in data:
                logger.error(f"æ— æ•ˆçš„è§„åˆ™æ–‡ä»¶: {file_path}")
                return 0, [], []

            imported_count = 0
            skipped = []
            overwritten = []

            for rule_data in data['rules']:
                rule_id = rule_data['rule_id']

                if rule_id in self._rules:
                    if merge_strategy == "skip":
                        skipped.append(rule_id)
                        continue
                    elif merge_strategy == "skip_all":
                        skipped.append(rule_id)
                        continue
                    elif merge_strategy in ("overwrite", "overwrite_all"):
                        # å¤‡ä»½åŸè§„åˆ™
                        self._backup_rule(rule_id)
                        overwritten.append(rule_id)
                    else:
                        skipped.append(rule_id)
                        continue

                # ååºåˆ—åŒ–å¹¶æ·»åŠ 
                rule = CleanupRule.from_dict(rule_data)
                self._rules[rule_id] = rule
                imported_count += 1
                logger.info(f"å¯¼å…¥è§„åˆ™: {rule.rule_name} ({rule_id})")

            self._save_rules()
            self._reload_rules_to_engine()

            return imported_count, skipped, overwritten
        except (OSError, IOError, json.JSONDecodeError) as e:
            logger.error(f"å¯¼å…¥è§„åˆ™å¤±è´¥: {e}")
            return 0, [], []

    # ------------------------------------------------------------------------
    # é¢„ç½®è§„åˆ™
    # ------------------------------------------------------------------------

    def load_preset_rules(self) -> int:
        """åŠ è½½é¢„ç½®è§„åˆ™åº“

        Returns:
            åŠ è½½çš„è§„åˆ™æ•°
        """
        if not self.preset_rules_file.exists():
            # åˆ›å»ºé»˜è®¤é¢„ç½®è§„åˆ™
            self._create_default_preset_rules()

        try:
            with open(self.preset_rules_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if 'rules' not in data:
                return 0

            count = 0
            for rule_data in data['rules']:
                rule = CleanupRule.from_dict(rule_data)
                rule_id = f"preset_{rule.rule_id}"

                if rule_id not in self._rules:
                    self._rules[rule_id] = rule
                    count += 1

            self._reload_rules_to_engine()
            logger.info(f"åŠ è½½äº† {count} æ¡é¢„ç½®è§„åˆ™")

            return count
        except (OSError, IOError, json.JSONDecodeError) as e:
            logger.error(f"åŠ è½½é¢„ç½®è§„åˆ™å¤±è´¥: {e}")
            return 0

    def add_to_presets(self, rule_id: str) -> bool:
        """å°†è§„åˆ™æ·»åŠ åˆ°é¢„ç½®è§„åˆ™åº“

        Args:
            rule_id: è§„åˆ™ ID

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if rule_id not in self._rules:
            logger.warning(f"è§„åˆ™ä¸å­˜åœ¨: {rule_id}")
            return False

        rule = self._rules[rule_id]

        # è¯»å–ç°æœ‰é¢„ç½®è§„åˆ™
        presets = {'rules': []}
        if self.preset_rules_file.exists():
            with open(self.preset_rules_file, 'r', encoding='utf-8') as f:
                presets = json.load(f)

        # æ·»åŠ æ–°è§„åˆ™
        rule_data = rule.to_dict()
        rule_data['rule_id'] = rule_data['rule_id'].replace('preset_', '')
        presets['rules'].append(rule_data)

        # ä¿å­˜
        with open(self.preset_rules_file, 'w', encoding='utf-8') as f:
            json.dump(presets, f, indent=2, ensure_ascii=False)

        logger.info(f"è§„åˆ™å·²æ·»åŠ åˆ°é¢„ç½®åº“: {rule.rule_name}")
        return True

    def list_preset_rules(self) -> List[Dict]:
        """åˆ—å‡ºå¯ç”¨çš„é¢„ç½®è§„åˆ™ï¼ˆæœªå¯¼å…¥çš„ï¼‰

        Returns:
            é¢„ç½®è§„åˆ™åˆ—è¡¨
        """
        if not self.preset_rules_file.exists():
            return []

        with open(self.preset_rules_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        presets = []
        for rule_data in data.get('rules', []):
            preset_id = f"preset_{rule_data['rule_id']}"
            is_imported = preset_id in self._rules

            presets.append({
                'rule_id': rule_data['rule_id'],
                'rule_name': rule_data['rule_name'],
                'description': rule_data.get('description', ''),
                'is_imported': is_imported
            })

        return presets

    # ------------------------------------------------------------------------
    # æŒä¹…åŒ–ï¼ˆç§æœ‰æ–¹æ³•ï¼‰
    # ------------------------------------------------------------------------

    def load_all_rules(self) -> int:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰è§„åˆ™

        Returns:
            åŠ è½½çš„è§„åˆ™æ•°
        """
        if not self.rules_file.exists():
            logger.info("è§„åˆ™æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶")
            self._save_rules()
            return 0

        try:
            with open(self.rules_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if 'rules' not in data:
                logger.warning("è§„åˆ™æ–‡ä»¶æ ¼å¼æ— æ•ˆï¼Œé‡æ–°åˆ›å»º")
                self._save_rules()
                return 0

            count = 0
            for rule_data in data['rules']:
                rule = CleanupRule.from_dict(rule_data)
                self._rules[rule.rule_id] = rule
                count += 1

            # åŠ è½½åˆ°å¼•æ“
            self._reload_rules_to_engine()

            logger.info(f"ä»æ–‡ä»¶åŠ è½½äº† {count} æ¡è§„åˆ™")
            return count
        except (OSError, IOError, json.JSONDecodeError) as e:
            logger.error(f"åŠ è½½è§„åˆ™å¤±è´¥: {e}")
            return 0

    def _save_rules(self) -> bool:
        """ä¿å­˜è§„åˆ™åˆ°é…ç½®æ–‡ä»¶

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            data = {
                'version': '1.0',
                'last_updated': datetime.now().isoformat(),
                'count': len(self._rules),
                'rules': [rule.to_dict() for rule in self._rules.values()]
            }

            with open(self.rules_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            return True
        except (OSError, IOError) as e:
            logger.error(f"ä¿å­˜è§„åˆ™å¤±è´¥: {e}")
            return False

    def _reload_rules_to_engine(self):
        """é‡æ–°åŠ è½½è§„åˆ™åˆ°å¼•æ“ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        self.engine.load_rules(list(self._rules.values()))

    def _backup_rule(self, rule_id: str):
        """å¤‡ä»½è§„åˆ™ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        Args:
            rule_id: è§„åˆ™ ID
        """
        if rule_id not in self._rules:
            return

        rule = self._rules[rule_id]
        backup_file = self.backup_dir / f"{rule_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(rule.to_dict(), f, indent=2, ensure_ascii=False)

        logger.info(f"å¤‡ä»½è§„åˆ™åˆ°: {backup_file}")

    def _create_default_preset_rules(self):
        """åˆ›å»ºé»˜è®¤é¢„ç½®è§„åˆ™åº“ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        from .cleanup_rule import ConditionType

        # å®šä¹‰ 5 æ¡å¸¸ç”¨è§„åˆ™
        preset_rules = [
            {
                'rule_id': 'temp_files_large',
                'rule_name': 'å¤§ä¸´æ—¶æ–‡ä»¶æ¸…ç†',
                'description': 'åˆ é™¤è¶…è¿‡ 10MB çš„ä¸´æ—¶æ–‡ä»¶ï¼ˆ.tmp, .tempï¼‰',
                'rule_type': RuleType.FILE_SIZE.value,
                'conditions': [
                    {
                        'condition_type': ConditionType.FILE_EXTENSION.value,
                        'operator': 'in',
                        'value': ['tmp', 'temp'],
                        'is_case_sensitive': False
                    },
                    {
                        'condition_type': ConditionType.FILE_SIZE.value,
                        'operator': 'greater_than',
                        'value': 10485760,  # 10 MB
                        'is_case_sensitive': False
                    }
                ],
                'action': RuleAction.DELETE.value,
                'is_enabled': True,
                'priority': 0,
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            },
            {
                'rule_id': 'log_files_old',
                'rule_name': 'æ—§æ—¥å¿—æ–‡ä»¶æ¸…ç†',
                'description': 'åˆ é™¤è¶…è¿‡ 7 å¤©çš„æ—¥å¿—æ–‡ä»¶ï¼ˆ.logï¼‰',
                'rule_type': RuleType.DATE_MODIFIED.value,
                'conditions': [
                    {
                        'condition_type': ConditionType.FILE_EXTENSION.value,
                        'operator': 'equals',
                        'value': 'log',
                        'is_case_sensitive': False
                    },
                    {
                        'condition_type': ConditionType.DATE_MODIFIED.value,
                        'operator': 'before',
                        'value': (datetime.now() - timedelta(days=7)).isoformat(),
                        'is_case_sensitive': False
                    }
                ],
                'action': RuleAction.DELETE.value,
                'is_enabled': True,
                'priority': 1,
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            }
        ]

        data = {'rules': preset_rules}

        with open(self.preset_rules_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        logger.info("åˆ›å»ºé»˜è®¤é¢„ç½®è§„åˆ™åº“")


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def get_common_rules() -> List[CleanupRule]:
    """è·å–å¸¸ç”¨æ¸…ç†è§„åˆ™åˆ—è¡¨

    Returns:
        å¸¸ç”¨è§„åˆ™åˆ—è¡¨
    """
    rules = []
    rules.append(create_simple_rule(
        rule_id="common_temp",
        rule_name="ä¸´æ—¶æ–‡ä»¶æ¸…ç†",
        description="ä¸´æ—¶æ–‡ä»¶å’Œç¼“å­˜",
        rule_type=RuleType.FILE_EXTENSION,
        condition_type=ConditionType.FILE_EXTENSION,
        operator=RuleOperator.IN,
        value=["tmp", "temp", "cache", "dmp"],
        action=RuleAction.DELETE
    ))

    rules.append(create_simple_rule(
        rule_id="common_log",
        rule_name="æ—¥å¿—æ–‡ä»¶æ¸…ç†",
        description="åº”ç”¨å’Œç³»ç»Ÿæ—¥å¿—",
        rule_type=RuleType.FILE_EXTENSION,
        condition_type=ConditionType.FILE_EXTENSION,
        operator=RuleOperator.EQUALS,
        value="log",
        action=RuleAction.DELETE
    ))

    return rules


def get_scenario_rules(scenario: str) -> List[CleanupRule]:
    """è·å–åœºæ™¯åŒ–è§„åˆ™

    Args:
        scenario: åœºæ™¯ç±»å‹ï¼ˆgamer, office, developer, normalï¼‰

    Returns:
        è§„åˆ™åˆ—è¡¨
    """
    rules = []

    if scenario == "gamer":
        rules.append(create_simple_rule(
            rule_id="gamer_cache",
            rule_name="æ¸¸æˆç¼“å­˜æ¸…ç†",
            description="æ¸¸æˆç¼“å­˜æ–‡ä»¶",
            rule_type=RuleType.PATH_PATTERN,
            condition_type=ConditionType.FILE_PATH,
            operator=RuleOperator.CONTAINS,
            value="cache",
            action=RuleAction.DELETE
        ))
    elif scenario == "office":
        rules.append(create_simple_rule(
            rule_id="office_temp",
            rule_name="åŠå…¬ä¸´æ—¶æ–‡ä»¶",
            description="Office ä¸´æ—¶æ–‡ä»¶",
            rule_type=RuleType.FILE_EXTENSION,
            condition_type=ConditionType.FILE_EXTENSION,
            operator=RuleOperator.EQUALS,
            value="tmp",
            action=RuleAction.DELETE
        ))
    elif scenario == "developer":
        rules.append(create_simple_rule(
            rule_id="dev_build_cache",
            rule_name="æ„å»ºç¼“å­˜æ¸…ç†",
            description="ç”Ÿæˆæ–‡ä»¶å’Œæ„å»ºç¼“å­˜",
            rule_type=RuleType.FILE_EXTENSION,
            condition_type=ConditionType.FILE_EXTENSION,
            operator=RuleOperator.IN,
            value=["pyc", "o", "so", "dll"],
            action=RuleAction.DELETE
        ))
    elif scenario == "normal":
        # æ™®é€šç”¨æˆ·åœºæ™¯ï¼šæµè§ˆå™¨ç¼“å­˜ã€ä¸‹è½½æ–‡ä»¶
        rules.append(create_simple_rule(
            rule_id="normal_browser_cache",
            rule_name="æµè§ˆå™¨ç¼“å­˜",
            description="æµè§ˆå™¨ç¼“å­˜æ–‡ä»¶",
            rule_type=RuleType.PATH_PATTERN,
            condition_type=ConditionType.FILE_PATH,
            operator=RuleOperator.CONTAINS,
            value="cache",
            action=RuleAction.DELETE
        ))

    return rules
